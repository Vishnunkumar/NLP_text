{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import simpletransformers\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarf = tarfile.open('gpt_personachat_cache.tar.gz')\n",
    "tarf.extractall()\n",
    "tarf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.conv_ai import ConvAIModel\n",
    "\n",
    "\n",
    "train_args = {\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"reprocess_input_data\": True\n",
    "}\n",
    "\n",
    "# Create a ConvAIModel\n",
    "model = ConvAIModel(\"gpt\", \"gpt_personachat_cache\", use_cuda=False, args=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fb364023844dc6aab2a91e0aebafb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7a50642e7c450cb163b729606ddb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec07e2074b1441949eb2874659c1233d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Running Epoch 0 of 1'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/transformers/modeling_openai.py:690: FutureWarning: The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 4.129050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train_model(\"data/train.json\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir=True, manual_seed=42)\n",
    "model = ClassificationModel(model_type='distilbert', model_name='distilbert-base-cased', \n",
    "                            use_cuda=False, num_labels=2, args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(simpletransformers.classification.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=10000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
    "    split=' ', char_level=False, oov_token=None, document_count=0)\n",
    "tokenizer.fit_on_texts(df_train['text'])\n",
    "train_seq = np.array(tokenizer.texts_to_sequences(df_train['text']))\n",
    "train_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seq, padding='post')\n",
    "train_vector = np.reshape(train_vector, (train_vector.shape[0], 1, train_vector.shape[1])).astype(float)\n",
    "train_y = np.array(labels).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x, va_x, tr_y, va_y = train_test_split(train_vector, train_y, stratify=train_y, random_state=342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(128, input_shape = tr_x.shape[1:], return_sequences=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "179/179 [==============================] - 2s 11ms/step - loss: 0.7500 - accuracy: 0.5658 - val_loss: 0.7389 - val_accuracy: 0.5704\n",
      "Epoch 2/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.7252 - accuracy: 0.5703 - val_loss: 0.7147 - val_accuracy: 0.5704\n",
      "Epoch 3/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.7041 - accuracy: 0.5703 - val_loss: 0.7003 - val_accuracy: 0.5704\n",
      "Epoch 4/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6957 - accuracy: 0.5703 - val_loss: 0.6957 - val_accuracy: 0.5704\n",
      "Epoch 5/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5703 - val_loss: 0.6943 - val_accuracy: 0.5704\n",
      "Epoch 6/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.5702 - val_loss: 0.6938 - val_accuracy: 0.5709\n",
      "Epoch 7/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6916 - accuracy: 0.5716 - val_loss: 0.6938 - val_accuracy: 0.5735\n",
      "Epoch 8/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6908 - accuracy: 0.5735 - val_loss: 0.6939 - val_accuracy: 0.5735\n",
      "Epoch 9/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6897 - accuracy: 0.5735 - val_loss: 0.6940 - val_accuracy: 0.5735\n",
      "Epoch 10/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6880 - accuracy: 0.5756 - val_loss: 0.6944 - val_accuracy: 0.5751\n",
      "Epoch 11/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6860 - accuracy: 0.5807 - val_loss: 0.6944 - val_accuracy: 0.5777\n",
      "Epoch 12/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6841 - accuracy: 0.5933 - val_loss: 0.6947 - val_accuracy: 0.5767\n",
      "Epoch 13/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6821 - accuracy: 0.6034 - val_loss: 0.6946 - val_accuracy: 0.5798\n",
      "Epoch 14/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6798 - accuracy: 0.6106 - val_loss: 0.6945 - val_accuracy: 0.5872\n",
      "Epoch 15/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6776 - accuracy: 0.6253 - val_loss: 0.6947 - val_accuracy: 0.5914\n",
      "Epoch 16/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6752 - accuracy: 0.6348 - val_loss: 0.6943 - val_accuracy: 0.5966\n",
      "Epoch 17/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6729 - accuracy: 0.6423 - val_loss: 0.6946 - val_accuracy: 0.6008\n",
      "Epoch 18/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6704 - accuracy: 0.6506 - val_loss: 0.6954 - val_accuracy: 0.6003\n",
      "Epoch 19/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6684 - accuracy: 0.6549 - val_loss: 0.6959 - val_accuracy: 0.6019\n",
      "Epoch 20/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6660 - accuracy: 0.6619 - val_loss: 0.6959 - val_accuracy: 0.5982\n",
      "Epoch 21/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6634 - accuracy: 0.6703 - val_loss: 0.6964 - val_accuracy: 0.5987\n",
      "Epoch 22/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6618 - accuracy: 0.6728 - val_loss: 0.6989 - val_accuracy: 0.5924\n",
      "Epoch 23/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6598 - accuracy: 0.6821 - val_loss: 0.6994 - val_accuracy: 0.5951\n",
      "Epoch 24/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6579 - accuracy: 0.6868 - val_loss: 0.6993 - val_accuracy: 0.5919\n",
      "Epoch 25/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6560 - accuracy: 0.6921 - val_loss: 0.6988 - val_accuracy: 0.5977\n",
      "Epoch 26/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6544 - accuracy: 0.6943 - val_loss: 0.7003 - val_accuracy: 0.5930\n",
      "Epoch 27/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6524 - accuracy: 0.7012 - val_loss: 0.7003 - val_accuracy: 0.5930\n",
      "Epoch 28/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6507 - accuracy: 0.7082 - val_loss: 0.7025 - val_accuracy: 0.5867\n",
      "Epoch 29/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6484 - accuracy: 0.7145 - val_loss: 0.7020 - val_accuracy: 0.5909\n",
      "Epoch 30/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6468 - accuracy: 0.7162 - val_loss: 0.7044 - val_accuracy: 0.5945\n",
      "Epoch 31/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.7255 - val_loss: 0.7031 - val_accuracy: 0.5961\n",
      "Epoch 32/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6430 - accuracy: 0.7255 - val_loss: 0.7036 - val_accuracy: 0.5977\n",
      "Epoch 33/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6411 - accuracy: 0.7301 - val_loss: 0.7049 - val_accuracy: 0.5919\n",
      "Epoch 34/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6394 - accuracy: 0.7348 - val_loss: 0.7042 - val_accuracy: 0.5903\n",
      "Epoch 35/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6379 - accuracy: 0.7392 - val_loss: 0.7030 - val_accuracy: 0.5998\n",
      "Epoch 36/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6365 - accuracy: 0.7429 - val_loss: 0.7060 - val_accuracy: 0.5977\n",
      "Epoch 37/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6350 - accuracy: 0.7488 - val_loss: 0.7027 - val_accuracy: 0.6014\n",
      "Epoch 38/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6341 - accuracy: 0.7499 - val_loss: 0.7041 - val_accuracy: 0.5982\n",
      "Epoch 39/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6329 - accuracy: 0.7523 - val_loss: 0.7043 - val_accuracy: 0.5977\n",
      "Epoch 40/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6312 - accuracy: 0.7567 - val_loss: 0.7065 - val_accuracy: 0.5940\n",
      "Epoch 41/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6299 - accuracy: 0.7592 - val_loss: 0.7063 - val_accuracy: 0.5940\n",
      "Epoch 42/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6281 - accuracy: 0.7642 - val_loss: 0.7091 - val_accuracy: 0.5888\n",
      "Epoch 43/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.7674 - val_loss: 0.7083 - val_accuracy: 0.5930\n",
      "Epoch 44/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6259 - accuracy: 0.7718 - val_loss: 0.7060 - val_accuracy: 0.5951\n",
      "Epoch 45/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6245 - accuracy: 0.7747 - val_loss: 0.7052 - val_accuracy: 0.5940\n",
      "Epoch 46/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6236 - accuracy: 0.7767 - val_loss: 0.7061 - val_accuracy: 0.5951\n",
      "Epoch 47/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6219 - accuracy: 0.7800 - val_loss: 0.7090 - val_accuracy: 0.5966\n",
      "Epoch 48/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.7842 - val_loss: 0.7081 - val_accuracy: 0.5966\n",
      "Epoch 49/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.7865 - val_loss: 0.7112 - val_accuracy: 0.5951\n",
      "Epoch 50/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6190 - accuracy: 0.7865 - val_loss: 0.7074 - val_accuracy: 0.6008\n",
      "Epoch 51/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6182 - accuracy: 0.7889 - val_loss: 0.7071 - val_accuracy: 0.6035\n",
      "Epoch 52/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6176 - accuracy: 0.7896 - val_loss: 0.7087 - val_accuracy: 0.5998\n",
      "Epoch 53/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6169 - accuracy: 0.7930 - val_loss: 0.7071 - val_accuracy: 0.6014\n",
      "Epoch 54/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.7979 - val_loss: 0.7055 - val_accuracy: 0.6024\n",
      "Epoch 55/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.7968 - val_loss: 0.7077 - val_accuracy: 0.6045\n",
      "Epoch 56/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6140 - accuracy: 0.7996 - val_loss: 0.7061 - val_accuracy: 0.6019\n",
      "Epoch 57/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6140 - accuracy: 0.7994 - val_loss: 0.7064 - val_accuracy: 0.6029\n",
      "Epoch 58/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6130 - accuracy: 0.8015 - val_loss: 0.7085 - val_accuracy: 0.5993\n",
      "Epoch 59/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6117 - accuracy: 0.8052 - val_loss: 0.7083 - val_accuracy: 0.6040\n",
      "Epoch 60/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6115 - accuracy: 0.8056 - val_loss: 0.7076 - val_accuracy: 0.6024\n",
      "Epoch 61/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6102 - accuracy: 0.8089 - val_loss: 0.7070 - val_accuracy: 0.6056\n",
      "Epoch 62/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6096 - accuracy: 0.8101 - val_loss: 0.7083 - val_accuracy: 0.6040\n",
      "Epoch 63/70\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6083 - accuracy: 0.8135 - val_loss: 0.7098 - val_accuracy: 0.5961\n",
      "Epoch 64/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6080 - accuracy: 0.8140 - val_loss: 0.7099 - val_accuracy: 0.6024\n",
      "Epoch 65/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6076 - accuracy: 0.8150 - val_loss: 0.7098 - val_accuracy: 0.5982\n",
      "Epoch 66/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6071 - accuracy: 0.8161 - val_loss: 0.7072 - val_accuracy: 0.6014\n",
      "Epoch 67/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6058 - accuracy: 0.8175 - val_loss: 0.7095 - val_accuracy: 0.6008\n",
      "Epoch 68/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6056 - accuracy: 0.8182 - val_loss: 0.7122 - val_accuracy: 0.5961\n",
      "Epoch 69/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6044 - accuracy: 0.8219 - val_loss: 0.7097 - val_accuracy: 0.5940\n",
      "Epoch 70/70\n",
      "179/179 [==============================] - 1s 5ms/step - loss: 0.6038 - accuracy: 0.8233 - val_loss: 0.7117 - val_accuracy: 0.5987\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tr_x, tr_y, epochs=70, validation_data=(va_x, va_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 128)            82432     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 256)            16640     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 107,585\n",
      "Trainable params: 107,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
