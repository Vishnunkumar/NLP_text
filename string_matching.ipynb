{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DeezyMatch'...\n",
      "remote: Enumerating objects: 186, done.\u001b[K\n",
      "remote: Counting objects: 100% (186/186), done.\u001b[K\n",
      "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
      "remote: Total 1523 (delta 109), reused 112 (delta 57), pack-reused 1337\u001b[K\n",
      "Receiving objects: 100% (1523/1523), 2.03 MiB | 27.72 MiB/s, done.\n",
      "Resolving deltas: 100% (990/990), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Living-with-machines/DeezyMatch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/vishnu-dev/repo/notebook_dir/text/string_match/DeezyMatch\n"
     ]
    }
   ],
   "source": [
    "cd DeezyMatch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./inputs/input_dfm.yaml\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;31mGPU was requested but not available.\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread CSV file: dataset/dataset-string-similarity_test.txt\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mnumber of labels, True: 4998 and False: 4997\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mSplitting the Dataset\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mfinish splitting the Dataset. User time: 0.023738861083984375\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32msplits are as follow:\n",
      "train    6997\n",
      "test     1500\n",
      "val      1498\n",
      "Name: split, dtype: int64\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mstart creating a lookup table and convert characters to indices\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32m-- create vocabulary\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32m-- convert tokens to indices\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32m-- create a lookup table for tokens\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:33\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32m-- read list of characters from ./dataset/characters_v001.vocab\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s2 padding:   0%|          | 0/6997 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32m-- Length of vocabulary: 7542\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[95m******************************\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[95m**** (Bi-directional) GRU ****\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[95m******************************\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread inputs\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mcreate a two_parallel_rnns model\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mstart fitting parameters\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mNumber of batches: 28\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:34\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mNumber of epochs: 5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354bc8bd73da423295c027c91626bc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4824df9d8347109325153fe7df8891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "Total number of params: 627243\n",
      "\n",
      "two_parallel_rnns (\n",
      "  (emb): Embedding(7542, 60), weights=((7542, 60),), parameters=452520\n",
      "  (rnn_1): GRU(60, 60, num_layers=2, dropout=0.01, bidirectional=True), weights=((180, 60), (180, 60), (180,), (180,), (180, 60), (180, 60), (180,), (180,), (180, 120), (180, 60), (180,), (180,), (180, 120), (180, 60), (180,), (180,)), parameters=109440\n",
      "  (attn_step1): Linear(in_features=120, out_features=60, bias=True), weights=((60, 120), (60,)), parameters=7260\n",
      "  (attn_step2): Linear(in_features=60, out_features=1, bias=True), weights=((1, 60), (1,)), parameters=61\n",
      "  (fc1): Linear(in_features=480, out_features=120, bias=True), weights=((120, 480), (120,)), parameters=57720\n",
      "  (fc2): Linear(in_features=120, out_features=2, bias=True), weights=((2, 120), (2,)), parameters=242\n",
      ")\n",
      "====================\n",
      "\n",
      "\n",
      "\u001b[92m2020-11-25 15:37:51\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[0;33m11/25/2020_15:37:51 -- Epoch: 1/5; Train; loss: 0.694; acc: 0.503; precision: 0.503, recall: 0.486, macrof1: 0.503, weightedf1: 0.503\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fc1a1e595c41af9bdadb79fcfb166e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:37:51\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;31m11/25/2020_15:37:51 -- Epoch: 1/5; Valid; loss: 0.693; acc: 0.497; precision: 0.481, recall: 0.067, macrof1: 0.383, weightedf1: 0.383\u001b[0m\n",
      "\u001b[92m2020-11-25 15:37:51\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32msaving the model\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcdd2a415304185973f5b2ec7c63ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:38:07\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[0;33m11/25/2020_15:38:07 -- Epoch: 2/5; Train; loss: 0.687; acc: 0.547; precision: 0.543, recall: 0.596, macrof1: 0.546, weightedf1: 0.546\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d39177351d8495fa6379e84dab70de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:38:08\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;31m11/25/2020_15:38:08 -- Epoch: 2/5; Valid; loss: 0.684; acc: 0.541; precision: 0.538, recall: 0.571, macrof1: 0.540, weightedf1: 0.540\u001b[0m\n",
      "\u001b[92m2020-11-25 15:38:08\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32msaving the model\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016f33486be147cfb4365ef732eeeea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:38:24\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[0;33m11/25/2020_15:38:24 -- Epoch: 3/5; Train; loss: 0.660; acc: 0.617; precision: 0.621, recall: 0.604, macrof1: 0.617, weightedf1: 0.617\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd257a3d7a7d4d32bba2ef6773efe47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:38:25\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;31m11/25/2020_15:38:25 -- Epoch: 3/5; Valid; loss: 0.640; acc: 0.646; precision: 0.619, recall: 0.757, macrof1: 0.641, weightedf1: 0.641\u001b[0m\n",
      "\u001b[92m2020-11-25 15:38:25\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32msaving the model\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1137cda1d8425d81a556354a1576de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:38:41\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[0;33m11/25/2020_15:38:41 -- Epoch: 4/5; Train; loss: 0.595; acc: 0.694; precision: 0.673, recall: 0.753, macrof1: 0.693, weightedf1: 0.693\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0b0582880d46c79fa1716787576ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:38:42\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;31m11/25/2020_15:38:42 -- Epoch: 4/5; Valid; loss: 0.602; acc: 0.685; precision: 0.677, recall: 0.708, macrof1: 0.685, weightedf1: 0.685\u001b[0m\n",
      "\u001b[92m2020-11-25 15:38:42\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32msaving the model\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b74f0c416d4af0b1ee3c791ab6df34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:38:58\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[0;33m11/25/2020_15:38:58 -- Epoch: 5/5; Train; loss: 0.546; acc: 0.731; precision: 0.713, recall: 0.771, macrof1: 0.730, weightedf1: 0.730\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69333be0034411f84aca80fe8e7fca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:38:58\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;31m11/25/2020_15:38:58 -- Epoch: 5/5; Valid; loss: 0.586; acc: 0.706; precision: 0.699, recall: 0.722, macrof1: 0.706, weightedf1: 0.706\u001b[0m\n",
      "\u001b[92m2020-11-25 15:38:58\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32msaving the model\u001b[0m\n",
      "\n",
      "\u001b[92m2020-11-25 15:38:58\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32msaving the model with least valid loss (checkpoint: 5) at ./models/test001/test001.model\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "User time: 84.5670\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "from DeezyMatch import train as dm_train\n",
    "\n",
    "# train a new model\n",
    "dm_train(input_file_path=\"./inputs/input_dfm.yaml\", \n",
    "         dataset_path=\"dataset/dataset-string-similarity_test.txt\", \n",
    "         model_name=\"test001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:40:52\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./inputs/input_dfm.yaml\u001b[0m\n",
      "\u001b[92m2020-11-25 15:40:52\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;31mGPU was requested but not available.\u001b[0m\n",
      "\u001b[92m2020-11-25 15:40:52\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\u001b[92m2020-11-25 15:40:52\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread CSV file: dataset/dataset-string-similarity_test.txt\u001b[0m\n",
      "\u001b[92m2020-11-25 15:40:52\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mnumber of labels, True: 4998 and False: 4997\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s2 padding:   0%|          | 0/9995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:40:52\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mskipping 0 lines\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f267c188414ceda3c111d9bb72751e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2020-11-25 15:40:58\u001b[0m \u001b[95mip-172-16-126-63\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;31m11/25/2020_15:40:58 -- Epoch: 0/0; Test; loss: 0.532; acc: 0.751; precision: 0.747, recall: 0.760, macrof1: 0.751, weightedf1: 0.751\u001b[0m\n",
      "--- 5.851544141769409 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from DeezyMatch import inference as dm_inference\n",
    "\n",
    "# model inference using a model stored at pretrained_model_path and pretrained_vocab_path \n",
    "inf = dm_inference(input_file_path=\"./inputs/input_dfm.yaml\",\n",
    "             dataset_path=\"dataset/dataset-string-similarity_test.txt\", \n",
    "             pretrained_model_path=\"./models/test001/test001.model\", \n",
    "             pretrained_vocab_path=\"./models/test001/test001.vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
